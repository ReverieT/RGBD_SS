import argparse
import os
import sys
import time
import torch
import torch.nn as nn
import numpy as np

# æ·»åŠ è·¯å¾„
sys.path.append(os.getcwd())

from seg_core.models.backbones.dformer import DFormerv2_S, DFormerv2_B, DFormerv2_L

from seg_core.models.backbones.resnet import ResNet
from seg_core.models.decoders.fcn_head import FCNHead
from seg_core.models.segmentor import RGBDSegmentor
from seg_core.utils.config_parser import parse_config

try:
    from thop import profile, clever_format
except ImportError:
    print("âŒ Error: 'thop' library is not installed.")
    print("Please install it via: pip install thop")
    sys.exit(1)

# ==========================================
# è¾…åŠ© Wrapper
# Thop åªèƒ½ä¼ é€’ Tensor å‚æ•°ï¼Œè€Œæˆ‘ä»¬çš„æ¨¡å‹éœ€è¦ Dict
# ==========================================
class ModelWrapper(nn.Module):
    def __init__(self, model):
        super().__init__()
        self.model = model
    
    def forward(self, rgb, depth):
        # å°† Tensor é‡æ–°æ‰“åŒ…æˆå­—å…¸
        return self.model({'image': rgb, 'depth': depth})

def get_args():
    parser = argparse.ArgumentParser(description="Benchmark FPS, Params, and FLOPs")
    parser.add_argument("--config", required=True, help="Config file path")
    # é»˜è®¤ä½¿ç”¨ Config é‡Œçš„ crop_sizeï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨æŒ‡å®š
    parser.add_argument("--height", type=int, default=None, help="Inference image height")
    parser.add_argument("--width", type=int, default=None, help="Inference image width")
    return parser.parse_args()

def main():
    args = get_args()
    cfg = parse_config(args.config)
    
    # 1. ç¡®å®šè¾“å…¥å°ºå¯¸
    # å¦‚æœå‘½ä»¤è¡Œæ²¡æŒ‡å®šï¼Œå°±ç”¨ Config é‡Œçš„ crop_size (ä¾‹å¦‚ 480x480)
    # æ³¨æ„ï¼šResNet ç­‰æ¨¡å‹é€šå¸¸è¦æ±‚è¾“å…¥æ˜¯ 32 çš„å€æ•°
    h = args.height if args.height else cfg.transforms.crop_size
    w = args.width if args.width else cfg.transforms.crop_size
    
    print(f"ğŸš€ Starting Benchmark...")
    print(f"   Config: {args.config}")
    print(f"   Input Size: ({h}, {w})")
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # 4. æ„å»ºæ¨¡å‹
    if 'dformer' in cfg.model.backbone:
        # === å®ä¾‹åŒ– DFormer ===
        if cfg.model.backbone == 'dformerv2_s':
            backbone = DFormerv2_S(pretrained=cfg.model.pretrained)
            dec_channels = 512
        elif cfg.model.backbone == 'dformerv2_b':
            backbone = DFormerv2_B(pretrained=cfg.model.pretrained)
            dec_channels = 512
        # ... å…¶ä»–å˜ä½“
        head = FCNHead(in_channels=512, channels=cfg.model.decoder_channels, num_classes=cfg.dataset.n_classes)
        # â˜… å…³é”®ï¼šåªä¼ ä¸€ä¸ª backboneï¼ŒSegmentor ä¼šè‡ªåŠ¨è¯†åˆ« is_unified=True
        model = RGBDSegmentor(backbone, head=head, n_classes=cfg.dataset.n_classes)
    else:
        # === å®ä¾‹åŒ– ResNet ===
        rgb_backbone = ResNet(depth=50, pretrained=cfg.model.pretrained)
        depth_backbone = ResNet(depth=50, pretrained=cfg.model.pretrained)
        head = FCNHead(in_channels=2048, channels=cfg.model.decoder_channels, num_classes=cfg.dataset.n_classes)
        model = RGBDSegmentor(rgb_backbone, depth_backbone, head, cfg.dataset.n_classes)
    
    real_model = model
    real_model.eval()
    real_model.to(device)
    
    # 3. ç»Ÿè®¡å‚æ•°é‡ (Params)
    # è¿‡æ»¤æ‰ä¸éœ€è¦æ¢¯åº¦çš„å‚æ•°ï¼ˆå¦‚æœæœ‰å†»ç»“å±‚çš„è¯ï¼‰
    trainable_params = sum(p.numel() for p in real_model.parameters() if p.requires_grad)
    total_params = sum(p.numel() for p in real_model.parameters())
    
    print("\n" + "="*30)
    print(f"ğŸ“Š Model Parameters")
    print(f"   Total Params:     {total_params / 1e6:.2f} M")
    print(f"   Trainable Params: {trainable_params / 1e6:.2f} M")

    # 4. ç»Ÿè®¡ FLOPs (è®¡ç®—å¤æ‚åº¦)
    # æ„é€  Dummy Input
    dummy_rgb = torch.randn(1, 3, h, w).to(device)
    dummy_depth = torch.randn(1, 1, h, w).to(device)
    
    # ä½¿ç”¨ Wrapper é€‚é… thop
    wrapped_model = ModelWrapper(real_model)
    
    try:
        flops, params = profile(wrapped_model, inputs=(dummy_rgb, dummy_depth), verbose=False)
        flops_readable, params_readable = clever_format([flops, params], "%.3f")
        print(f"   FLOPs (G):        {flops / 1e9:.3f} G")
        # print(f"   (Thop format: {flops_readable})")
    except Exception as e:
        print(f"   FLOPs Calculation Failed: {e}")

    # 5. æµ‹é€Ÿ (FPS)
    print("\n" + "="*30)
    print(f"â±ï¸  Measuring FPS (Batch Size = 1)...")
    
    # é¢„çƒ­ (Warm up) - è®© GPU è¿›å…¥å·¥ä½œçŠ¶æ€
    print("   Warming up GPU...")
    with torch.no_grad():
        for _ in range(50):
            _ = real_model({'image': dummy_rgb, 'depth': dummy_depth})
    
    # æ­£å¼è®¡æ—¶
    iterations = 200
    print(f"   Running {iterations} iterations...")
    
    # ä½¿ç”¨ torch.cuda.Event è¿›è¡Œç²¾ç¡®è®¡æ—¶
    starter = torch.cuda.Event(enable_timing=True)
    ender = torch.cuda.Event(enable_timing=True)
    
    timings = []
    
    with torch.no_grad():
        for _ in range(iterations):
            starter.record()
            _ = real_model({'image': dummy_rgb, 'depth': dummy_depth})
            ender.record()
            
            # ç­‰å¾… GPU å®Œæˆ
            torch.cuda.synchronize()
            curr_time = starter.elapsed_time(ender) # æ¯«ç§’
            timings.append(curr_time)
            
    mean_time_ms = np.mean(timings)
    std_time_ms = np.std(timings)
    fps = 1000 / mean_time_ms
    
    print(f"   Latency: {mean_time_ms:.2f} ms Â± {std_time_ms:.2f} ms")
    print(f"   FPS:     {fps:.2f}")
    print("="*30 + "\n")

if __name__ == '__main__':
    main()