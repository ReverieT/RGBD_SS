#!/bin/bash

# =========================================================
# ä½¿ç”¨æ–¹æ³•: 
# bash scripts/train_dist.sh <GPU_IDS> <CONFIG_PATH>
# ç¤ºä¾‹: 
# bash scripts/train_dist.sh 0,1 configs/nyu_v2/resnet50_baseline.yaml
# =========================================================

# 1. è·å–å‚æ•°
GPUS=$1
CONFIG=$2

# æ£€æŸ¥å‚æ•°æ˜¯å¦ä¸ºç©º
if [ -z "$GPUS" ] || [ -z "$CONFIG" ]; then
    echo "Usage: bash scripts/train_dist.sh <GPU_IDS> <CONFIG_PATH>"
    echo "Example: bash scripts/train_dist.sh 0,1 configs/nyu_v2/resnet50_baseline.yaml"
    exit 1
fi

# 2. è®¾ç½®ç¯å¢ƒå˜é‡
export CUDA_VISIBLE_DEVICES=$GPUS
# è®¾ç½®ä¸»ç«¯å£ (éšæœºç”Ÿæˆä¸€ä¸ªç«¯å£é˜²æ­¢å†²çªï¼Œæˆ–è€…å›ºå®š)
export MASTER_PORT=${MASTER_PORT:-29500}
# å°†å½“å‰ç›®å½•æ·»åŠ åˆ° PYTHONPATHï¼Œç¡®ä¿èƒ½ import seg_core
export PYTHONPATH="$(dirname $0)/..":$PYTHONPATH

# è®¡ç®— GPU æ•°é‡ (æ ¹æ®é€—å·åˆ†éš”ç¬¦è®¡ç®—)
GPU_COUNT=$(echo $GPUS | tr ',' '\n' | wc -l)

echo "ğŸš€ Launching training on GPUs: $GPUS (Count: $GPU_COUNT)"
echo "ğŸ“„ Using Config: $CONFIG"

# 3. å¯åŠ¨ torchrun
# --nproc_per_node: å¯åŠ¨çš„è¿›ç¨‹æ•°ï¼Œé€šå¸¸ç­‰äºæ˜¾å¡æ•°
torchrun \
    --nproc_per_node=$GPU_COUNT \
    --master_port=$MASTER_PORT \
    tools/train.py \
    --config $CONFIG
