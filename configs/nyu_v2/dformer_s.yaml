# 1. 继承基础配置
_base_:
  - "../_base_/datasets/nyu_v2.yaml"
  - "../_base_/schedules/default_schedule.yaml"

# 2. 模型特定配置
model:
  # 对应 train.py 中 if 'dformer' in cfg.model.backbone: 的判断逻辑
  backbone: "dformerv2_s"
  
  # ★★★ 关键：修改为你下载权重的实际绝对路径或相对路径 ★★★
  pretrained: "checkpoints/dformer_v2_s_imagenet.pth"
  
  # 解码头配置
  decoder: "fcn"
  decoder_channels: 256 # 中间特征维度，256 或 512 都可以

# 3. 覆写 Loader 配置
loader:
  # Transformer 显存占用比 ResNet 大，如果显存不够(如<24G)，建议设为 4
  batch_size: 4 
  num_workers: 4
  pin_memory: True

# 4. 覆写优化器 (Transformer 核心)
optimizer:
  type: "AdamW"    # SGD -> AdamW
  lr: 0.00006      # 6e-5 (ResNet通常用 0.01, 这里要小很多)
  momentum: 0.9    # AdamW 其实不用这个参数，但为了代码兼容保留无妨
  weight_decay: 0.01 # 权重衰减，防止过拟合

# 5. 覆写调度器
scheduler:
  type: "Poly"
  power: 1.0       # 线性衰减或 Poly 衰减皆可
  # 注意：train.py 目前使用的是简单的 PolynomialLR。
  # 如果后续发现训练初期 Loss 震荡剧烈，可能需要实现 Warmup 逻辑。

# 6. 其他
epochs: 500        # DFormer 论文中通常训练 500 epoch，ResNet 只要 50
print_freq: 20     # 打印频率
save_dir: "outputs/nyu_dformer_s"